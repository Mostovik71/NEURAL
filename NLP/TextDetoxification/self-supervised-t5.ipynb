{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom transformers import T5ForConditionalGeneration, T5Tokenizer, BertTokenizer, BertForSequenceClassification\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data import TensorDataset\nfrom tqdm import tqdm\nfrom transformers import AdamW\nfrom torch.nn import CrossEntropyLoss","metadata":{"id":"A1EWqAJqQlU9","execution":{"iopub.status.busy":"2022-05-19T05:19:52.324601Z","iopub.execute_input":"2022-05-19T05:19:52.32489Z","iopub.status.idle":"2022-05-19T05:19:52.336336Z","shell.execute_reply.started":"2022-05-19T05:19:52.324862Z","shell.execute_reply":"2022-05-19T05:19:52.335516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_model = 'cointegrated/rut5-small'\nmodel = T5ForConditionalGeneration.from_pretrained(raw_model, output_hidden_states=False)\ntokenizer = T5Tokenizer.from_pretrained(raw_model)\nberttokenizer = BertTokenizer.from_pretrained('SkolkovoInstitute/russian_toxicity_classifier')\nbertmodel = BertForSequenceClassification.from_pretrained('SkolkovoInstitute/russian_toxicity_classifier')","metadata":{"id":"HrZ6F-K2Qi2b","outputId":"0926aaae-8c0b-4dde-ed96-15d3f38bf15b","execution":{"iopub.status.busy":"2022-05-19T05:19:54.712075Z","iopub.execute_input":"2022-05-19T05:19:54.712355Z","iopub.status.idle":"2022-05-19T05:20:38.192266Z","shell.execute_reply.started":"2022-05-19T05:19:54.712327Z","shell.execute_reply":"2022-05-19T05:20:38.19138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text = 'тупой ты дурак'\nsattr = 'toxic: '\ndattr = 'civil: '\nencoded = berttokenizer.encode_plus(text, max_length=400,\n                                              pad_to_max_length=True,\n                                              return_attention_mask=False, return_tensors='pt', truncation=True)\nsattr = berttokenizer.encode_plus(sattr, max_length=400,\n                                              pad_to_max_length=True,\n                                              return_attention_mask=False, return_tensors='pt', truncation=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T05:38:12.951809Z","iopub.execute_input":"2022-05-19T05:38:12.952567Z","iopub.status.idle":"2022-05-19T05:38:12.962039Z","shell.execute_reply.started":"2022-05-19T05:38:12.952525Z","shell.execute_reply":"2022-05-19T05:38:12.961175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bertmodel","metadata":{"execution":{"iopub.status.busy":"2022-05-19T05:38:41.975552Z","iopub.execute_input":"2022-05-19T05:38:41.975949Z","iopub.status.idle":"2022-05-19T05:38:41.986489Z","shell.execute_reply.started":"2022-05-19T05:38:41.975918Z","shell.execute_reply":"2022-05-19T05:38:41.985476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#enc = model.encoder.embed_tokens(encoded.input_ids)\nbertenc = bertmodel.bert.embeddings(encoded.input_ids)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T05:39:17.757926Z","iopub.execute_input":"2022-05-19T05:39:17.758547Z","iopub.status.idle":"2022-05-19T05:39:17.769193Z","shell.execute_reply.started":"2022-05-19T05:39:17.758493Z","shell.execute_reply":"2022-05-19T05:39:17.768408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bertmodel.bert.encoder(bertenc).last_hidden_state[:, 0, :].shape","metadata":{"execution":{"iopub.status.busy":"2022-05-19T05:41:05.206452Z","iopub.execute_input":"2022-05-19T05:41:05.206952Z","iopub.status.idle":"2022-05-19T05:41:06.292745Z","shell.execute_reply.started":"2022-05-19T05:41:05.206918Z","shell.execute_reply":"2022-05-19T05:41:06.291951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h0 = model.encoder(inputs_embeds=enc).last_hidden_state[:, 0, :]","metadata":{"execution":{"iopub.status.busy":"2022-05-19T05:37:23.242095Z","iopub.execute_input":"2022-05-19T05:37:23.242389Z","iopub.status.idle":"2022-05-19T05:37:23.464469Z","shell.execute_reply.started":"2022-05-19T05:37:23.242358Z","shell.execute_reply":"2022-05-19T05:37:23.463617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.dense = torch.nn.Linear(768, 768)","metadata":{"execution":{"iopub.status.busy":"2022-05-17T13:59:50.791245Z","iopub.execute_input":"2022-05-17T13:59:50.792083Z","iopub.status.idle":"2022-05-17T13:59:50.810564Z","shell.execute_reply.started":"2022-05-17T13:59:50.792033Z","shell.execute_reply":"2022-05-17T13:59:50.809819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/2500selfsupervised/comms.csv')","metadata":{"id":"5DYYIeCxQi0F","execution":{"iopub.status.busy":"2022-05-17T13:59:53.846656Z","iopub.execute_input":"2022-05-17T13:59:53.847085Z","iopub.status.idle":"2022-05-17T13:59:53.907667Z","shell.execute_reply.started":"2022-05-17T13:59:53.84703Z","shell.execute_reply":"2022-05-17T13:59:53.90662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEVICE = 'cuda:0'","metadata":{"id":"1LwFjSToQixY","execution":{"iopub.status.busy":"2022-05-17T13:59:59.642237Z","iopub.execute_input":"2022-05-17T13:59:59.642498Z","iopub.status.idle":"2022-05-17T13:59:59.647096Z","shell.execute_reply.started":"2022-05-17T13:59:59.642468Z","shell.execute_reply":"2022-05-17T13:59:59.645751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dae(inputs: torch.Tensor) -> torch.Tensor:  # This function randomly masks and unmasks tokens #(Ошибка по прежнему здесь. Функция делает свои дела inplace)\n    rand = torch.rand(inputs.shape)\n    rand = rand.to(DEVICE)\n    mask_arr = (rand <= 0.15) * (inputs != 101) * (inputs != 102) * (inputs != 0) * (inputs != 1)\n    selection = torch.flatten((mask_arr[0]).nonzero()).tolist()\n    inputs[0, selection] = torch.randint_like(inputs[0, selection], low=32000, high=32100)\n\n    rand = torch.rand(inputs.shape)\n    rand = rand.to(DEVICE)\n    mask_arr = (rand <= 0.1) * (inputs <= 32100) * (inputs >= 32000)\n    selection = torch.flatten((mask_arr[0]).nonzero()).tolist()\n    inputs[0, selection] = torch.randint_like(inputs[0, selection], low=1, high=31999)\n    return inputs","metadata":{"id":"ZeYv8vo0Qiuv","execution":{"iopub.status.busy":"2022-05-19T05:15:04.739563Z","iopub.execute_input":"2022-05-19T05:15:04.740152Z","iopub.status.idle":"2022-05-19T05:15:04.751468Z","shell.execute_reply.started":"2022-05-19T05:15:04.740115Z","shell.execute_reply":"2022-05-19T05:15:04.750278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def waydae(comm, isxod, sattr):\n    nx = dae(comm)\n    xemb = model.shared(nx)\n    henc = model.encoder(inputs_embeds=xemb)\n    z = henc.last_hidden_state[:, 0, :]\n    z = model.dense(z)\n    h = z.view(4, 1, 512)#768 for base, 512 for small\n    emb = model.shared(torch.cat((sattr, isxod), 1))      \n    hdec = model.decoder(inputs_embeds=torch.add(emb, h))            \n    xdae = model.lm_head(hdec.last_hidden_state)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_to_dataset_torch(comment: pd.Series, sattribute: pd.Series, dattribute: pd.Series, tokenizer,\n                             DEVICE) -> TensorDataset:\n    input_ids1 = []\n    input_ids2 = []\n    input_ids3 = []\n    \n    for comm, sattr, dattr in tqdm(zip(comment, sattribute, dattribute)):\n        encoded_dict1 = tokenizer.encode_plus(comm, max_length=400,\n                                              pad_to_max_length=True,\n                                              return_attention_mask=False, return_tensors='pt', truncation=True)\n        input_ids1.append(encoded_dict1['input_ids'])\n\n        encoded_dict2 = tokenizer.encode_plus(sattr, max_length=15,\n                                              pad_to_max_length=True,\n                                              return_attention_mask=False, return_tensors='pt', truncation=True, add_special_tokens=False)\n        input_ids2.append(encoded_dict2['input_ids'])\n\n        encoded_dict3 = tokenizer.encode_plus(dattr, max_length=15,\n                                              pad_to_max_length=True,\n                                              return_attention_mask=False, return_tensors='pt', truncation=True, add_special_tokens=False)\n        input_ids3.append(encoded_dict3['input_ids'])\n\n    input_ids1 = torch.cat(input_ids1, dim=0)\n    input_ids2 = torch.cat(input_ids2, dim=0)\n    input_ids3 = torch.cat(input_ids3, dim=0)\n\n    input_ids1.to(dtype=torch.long)\n    input_ids2.to(dtype=torch.long)\n    input_ids3.to(dtype=torch.long)\n\n    return TensorDataset(input_ids1, input_ids2, input_ids3)\n","metadata":{"id":"PqI8LkDuQecu","execution":{"iopub.status.busy":"2022-05-17T14:00:05.700022Z","iopub.execute_input":"2022-05-17T14:00:05.700305Z","iopub.status.idle":"2022-05-17T14:00:05.712203Z","shell.execute_reply.started":"2022-05-17T14:00:05.700274Z","shell.execute_reply":"2022-05-17T14:00:05.710795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = convert_to_dataset_torch(df.comment, df.sattribute, df.dattribute, tokenizer, DEVICE)","metadata":{"id":"b6ujk5ELRsYC","outputId":"ae254423-7c84-4eb9-91bc-bce585f09854","execution":{"iopub.status.busy":"2022-05-17T14:00:09.581045Z","iopub.execute_input":"2022-05-17T14:00:09.581499Z","iopub.status.idle":"2022-05-17T14:00:12.024018Z","shell.execute_reply.started":"2022-05-17T14:00:09.581459Z","shell.execute_reply":"2022-05-17T14:00:12.023154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bs = 4\nloader = DataLoader(dataset, batch_size=bs, num_workers=0, shuffle=True)\nadamw_optimizer = AdamW(model.parameters(), lr=3e-5, eps=1e-8)","metadata":{"id":"mT8_fBW0RsTO","outputId":"20e48252-2270-4e80-e82b-40a92086dd57","execution":{"iopub.status.busy":"2022-05-17T14:00:15.073008Z","iopub.execute_input":"2022-05-17T14:00:15.07498Z","iopub.status.idle":"2022-05-17T14:00:15.088241Z","shell.execute_reply.started":"2022-05-17T14:00:15.074919Z","shell.execute_reply":"2022-05-17T14:00:15.087158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def training(model, optimizer):\n    ldae = 1\n    lcc = 1\n    model.to(DEVICE)\n    dataloader = loader\n    running_loss = 0.\n    epochs = 3\n    celoss = CrossEntropyLoss()\n    for epoch in range(epochs):\n        print(epoch)\n        for batch in tqdm(dataloader):\n                comm, sattr, dattr = batch  # Receiving comment, source attribute and destination attribute from batch\n                comm, sattr, dattr = comm.to(DEVICE), sattr.to(DEVICE), dattr.to(DEVICE)\n                isxod = comm.detach().clone()\n                optimizer.zero_grad()\n                # CC\n                inputs2 = torch.cat((dattr, isxod), 1)\n                \n                y = model.generate(inputs2)\n                \n                ccloss = model(input_ids=torch.cat((sattr, y), 1), decoder_input_ids=isxod, labels=isxod).loss\n                # DAE\n                \n                nx = dae(comm)\n\n                \n                xemb = model.shared(nx)\n                \n                henc = model.encoder(inputs_embeds=xemb)\n                z = henc.last_hidden_state[:, 0, :]\n                \n                z = model.dense(z)\n                h = z.view(4, 1, 768)#768 for base, 512 for small\n                emb = model.shared(torch.cat((sattr, isxod), 1))\n                \n                hdec = model.decoder(inputs_embeds=torch.add(emb, h))\n                \n                xdae = model.lm_head(hdec.last_hidden_state)\n                xdae = xdae[:, (-1+(xdae.shape[1]-isxod.shape[1])):-1, :]\n                \n                daeloss = celoss(xdae[0], isxod[0])\n\n                \n                loss = lcc * ccloss + ldae * daeloss #LOSS\n                \n                loss.backward()\n                \n                optimizer.step()\n                \n                running_loss += loss.item()\n        epoch_loss = running_loss / len(dataloader)\n\n        print('Loss: ' + str(epoch_loss))\n    return model","metadata":{"id":"soeEAE4_RsP3","execution":{"iopub.status.busy":"2022-05-17T14:05:58.284163Z","iopub.execute_input":"2022-05-17T14:05:58.284448Z","iopub.status.idle":"2022-05-17T14:05:58.300708Z","shell.execute_reply.started":"2022-05-17T14:05:58.284416Z","shell.execute_reply":"2022-05-17T14:05:58.298218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training(model, adamw_optimizer)","metadata":{"id":"z4hPHFehR4VG","outputId":"84f93962-a088-45cf-d453-fc84cf440690","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model, 'T5selfsupervised3eps.pth')","metadata":{"id":"Qd_C7gbqeSH9","execution":{"iopub.status.busy":"2022-05-17T14:37:58.084669Z","iopub.execute_input":"2022-05-17T14:37:58.085196Z","iopub.status.idle":"2022-05-17T14:37:59.559731Z","shell.execute_reply.started":"2022-05-17T14:37:58.085155Z","shell.execute_reply":"2022-05-17T14:37:59.55888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nimport string","metadata":{"execution":{"iopub.status.busy":"2022-05-17T14:42:05.206251Z","iopub.execute_input":"2022-05-17T14:42:05.206542Z","iopub.status.idle":"2022-05-17T14:42:05.213248Z","shell.execute_reply.started":"2022-05-17T14:42:05.206508Z","shell.execute_reply":"2022-05-17T14:42:05.212532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/100comms/test.tsv', sep='\\t')\ndf = df['toxic_comment']\n#df = df.apply(lambda x: re.sub('\\w*\\d\\w*', ' ', x))#Цифры\ndf = df.apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x))#Пунктуация\ndf = 'civil: '+df","metadata":{"execution":{"iopub.status.busy":"2022-05-17T14:43:03.267736Z","iopub.execute_input":"2022-05-17T14:43:03.268432Z","iopub.status.idle":"2022-05-17T14:43:03.289325Z","shell.execute_reply.started":"2022-05-17T14:43:03.268389Z","shell.execute_reply":"2022-05-17T14:43:03.288674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_dataset(toxic: pd.Series, tokenizer,\n                             DEVICE) -> TensorDataset:\n    input_ids1 = []\n    att_masks1 = []\n    \n    for tox in tqdm(toxic):\n        encoded_dict1 = tokenizer.encode_plus(tox, max_length=512,\n                                              pad_to_max_length=True,\n                                              return_attention_mask=True, return_tensors='pt', truncation=True)\n        input_ids1.append(encoded_dict1['input_ids'])\n        att_masks1.append(encoded_dict1['attention_mask'])\n\n    input_ids1 = torch.cat(input_ids1, dim=0)\n    att_masks1 = torch.cat(att_masks1, dim=0)\n  \n\n    input_ids1.to(DEVICE, dtype=torch.long)\n    att_masks1.to(DEVICE, dtype=torch.long)\n    \n\n    return TensorDataset(input_ids1, att_masks1) ","metadata":{"execution":{"iopub.status.busy":"2022-05-17T14:43:05.809384Z","iopub.execute_input":"2022-05-17T14:43:05.809665Z","iopub.status.idle":"2022-05-17T14:43:05.817734Z","shell.execute_reply.started":"2022-05-17T14:43:05.809632Z","shell.execute_reply":"2022-05-17T14:43:05.816679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = test_dataset(df, tokenizer, DEVICE)","metadata":{"execution":{"iopub.status.busy":"2022-05-17T14:43:08.729209Z","iopub.execute_input":"2022-05-17T14:43:08.7309Z","iopub.status.idle":"2022-05-17T14:43:08.792905Z","shell.execute_reply.started":"2022-05-17T14:43:08.730846Z","shell.execute_reply":"2022-05-17T14:43:08.79183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bs = 1\ntest_loader = DataLoader(dataset, batch_size=bs, num_workers=0, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-17T14:43:10.872268Z","iopub.execute_input":"2022-05-17T14:43:10.872529Z","iopub.status.idle":"2022-05-17T14:43:10.87734Z","shell.execute_reply.started":"2022-05-17T14:43:10.872499Z","shell.execute_reply":"2022-05-17T14:43:10.876216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = []\nmodel.eval()\nwith torch.no_grad():\n       for batch in tqdm(test_loader):\n                toxinps, toxmask = batch  \n                toxinps, toxmask = toxinps.to(DEVICE), toxmask.to(DEVICE)\n\n                generated_ids = model.generate(\n                  input_ids = toxinps,\n                  attention_mask = toxmask, \n                  max_length=150, \n                  num_beams=2,\n                  repetition_penalty=2.5, \n                  length_penalty=1.0, \n                  early_stopping=True\n                  )\n                pred = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n                predictions.append(pred)","metadata":{"execution":{"iopub.status.busy":"2022-05-17T14:43:12.746657Z","iopub.execute_input":"2022-05-17T14:43:12.747333Z","iopub.status.idle":"2022-05-17T14:43:33.076267Z","shell.execute_reply.started":"2022-05-17T14:43:12.747299Z","shell.execute_reply":"2022-05-17T14:43:33.075385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = pd.concat([df, pd.Series(predictions)], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-17T14:43:41.029227Z","iopub.execute_input":"2022-05-17T14:43:41.029486Z","iopub.status.idle":"2022-05-17T14:43:41.035594Z","shell.execute_reply.started":"2022-05-17T14:43:41.029455Z","shell.execute_reply":"2022-05-17T14:43:41.034758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.columns = ['toxic', 'civil']","metadata":{"execution":{"iopub.status.busy":"2022-05-17T14:43:43.721083Z","iopub.execute_input":"2022-05-17T14:43:43.721634Z","iopub.status.idle":"2022-05-17T14:43:43.726246Z","shell.execute_reply.started":"2022-05-17T14:43:43.721596Z","shell.execute_reply":"2022-05-17T14:43:43.725565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install openpyxl","metadata":{"execution":{"iopub.status.busy":"2022-05-17T14:43:47.107131Z","iopub.execute_input":"2022-05-17T14:43:47.107725Z","iopub.status.idle":"2022-05-17T14:44:00.212541Z","shell.execute_reply.started":"2022-05-17T14:43:47.107669Z","shell.execute_reply":"2022-05-17T14:44:00.211584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.to_excel('t5self-supervised3eps.xlsx')","metadata":{"execution":{"iopub.status.busy":"2022-05-17T14:44:07.049789Z","iopub.execute_input":"2022-05-17T14:44:07.050563Z","iopub.status.idle":"2022-05-17T14:44:07.285392Z","shell.execute_reply.started":"2022-05-17T14:44:07.050519Z","shell.execute_reply":"2022-05-17T14:44:07.284547Z"},"trusted":true},"execution_count":null,"outputs":[]}]}