{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom transformers import T5ForConditionalGeneration, T5Tokenizer\nimport os\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\nimport os\nimport random\nfrom tqdm import tqdm\nfrom torch.utils.data import TensorDataset\nimport re\nimport string\nfrom transformers import AdamW","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-14T15:57:54.375266Z","iopub.execute_input":"2022-05-14T15:57:54.375642Z","iopub.status.idle":"2022-05-14T15:58:00.97472Z","shell.execute_reply.started":"2022-05-14T15:57:54.375556Z","shell.execute_reply":"2022-05-14T15:58:00.973956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed = 1234):\n     random.seed(seed)\n     os.environ['PYTHONHASHSEED'] = str(seed)\n     np.random.seed(seed)     \n     torch.manual_seed(seed)\n     torch.cuda.manual_seed(seed)\n     torch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2022-05-14T15:58:08.386349Z","iopub.execute_input":"2022-05-14T15:58:08.387126Z","iopub.status.idle":"2022-05-14T15:58:08.39269Z","shell.execute_reply.started":"2022-05-14T15:58:08.387071Z","shell.execute_reply":"2022-05-14T15:58:08.391965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed_everything()","metadata":{"execution":{"iopub.status.busy":"2022-05-14T15:58:12.379078Z","iopub.execute_input":"2022-05-14T15:58:12.379727Z","iopub.status.idle":"2022-05-14T15:58:12.387132Z","shell.execute_reply.started":"2022-05-14T15:58:12.379688Z","shell.execute_reply":"2022-05-14T15:58:12.386296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_model = 'sberbank-ai/ruT5-base'\nmodel = T5ForConditionalGeneration.from_pretrained(raw_model, output_hidden_states=False)\ntokenizer = T5Tokenizer.from_pretrained(raw_model)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T15:58:15.246624Z","iopub.execute_input":"2022-05-14T15:58:15.246896Z","iopub.status.idle":"2022-05-14T15:59:46.077752Z","shell.execute_reply.started":"2022-05-14T15:58:15.246865Z","shell.execute_reply":"2022-05-14T15:59:46.077015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/toxic-russian-comments-from-pikabu-and-2ch/russian_comments_from_2ch_pikabu.csv')\ndf = df[['comment', 'toxic']]\ndf[\"comment\"] = df[\"comment\"].apply(lambda x: re.sub('\\w*\\d\\w*', ' ', x))\ndf[\"comment\"] = df[\"comment\"].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x))\ndf['comment'] = 'classify: '+df['comment']\ndf['toxic'] = df['toxic'].replace({1:'toxic', 0:'civil'})","metadata":{"execution":{"iopub.status.busy":"2022-05-14T15:59:58.772706Z","iopub.execute_input":"2022-05-14T15:59:58.77348Z","iopub.status.idle":"2022-05-14T15:59:59.887866Z","shell.execute_reply.started":"2022-05-14T15:59:58.773424Z","shell.execute_reply":"2022-05-14T15:59:59.887028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEVICE = 'cuda:0'","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:00:07.478085Z","iopub.execute_input":"2022-05-14T16:00:07.478785Z","iopub.status.idle":"2022-05-14T16:00:07.482365Z","shell.execute_reply.started":"2022-05-14T16:00:07.478743Z","shell.execute_reply":"2022-05-14T16:00:07.48161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_to_dataset_torch(comment: pd.Series, toxic: pd.Series, tokenizer,\n                             DEVICE) -> TensorDataset:\n    input_ids1 = []\n    input_ids2 = []\n    att_masks1 = []\n    att_masks2 = []\n    \n    for comm, tox in tqdm(zip(comment, toxic)):\n        encoded_dict1 = tokenizer.encode_plus(comm, max_length=512,\n                                              pad_to_max_length=True,\n                                              return_attention_mask=True, return_tensors='pt', truncation=True)\n        input_ids1.append(encoded_dict1['input_ids'])\n        att_masks1.append(encoded_dict1['attention_mask'])\n\n        encoded_dict2 = tokenizer.encode_plus(tox, max_length=512,\n                                              pad_to_max_length=True,\n                                              return_attention_mask=True, return_tensors='pt', truncation=True)\n        input_ids2.append(encoded_dict2['input_ids'])\n        att_masks2.append(encoded_dict2['attention_mask'])\n\n\n    input_ids1 = torch.cat(input_ids1, dim=0)\n    input_ids2 = torch.cat(input_ids2, dim=0)\n    att_masks1 = torch.cat(att_masks1, dim=0)\n    att_masks2 = torch.cat(att_masks2, dim=0)\n  \n\n    input_ids1.to(dtype=torch.long)\n    input_ids2.to(dtype=torch.long)\n    att_masks1.to(dtype=torch.long)\n    att_masks2.to(dtype=torch.long)\n    \n\n    return TensorDataset(input_ids1, input_ids2, att_masks1, att_masks2) ","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:00:15.567098Z","iopub.execute_input":"2022-05-14T16:00:15.567882Z","iopub.status.idle":"2022-05-14T16:00:15.577186Z","shell.execute_reply.started":"2022-05-14T16:00:15.567836Z","shell.execute_reply":"2022-05-14T16:00:15.576486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = convert_to_dataset_torch(df.comment, df.toxic, tokenizer, DEVICE)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:00:29.699097Z","iopub.execute_input":"2022-05-14T16:00:29.699362Z","iopub.status.idle":"2022-05-14T16:00:44.612355Z","shell.execute_reply.started":"2022-05-14T16:00:29.699332Z","shell.execute_reply":"2022-05-14T16:00:44.611588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bs = 4\nloader = DataLoader(dataset, batch_size=bs, num_workers=0, shuffle=True)\nadamw_optimizer = AdamW(model.parameters(), lr=3e-5, eps=1e-8)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:01:00.315901Z","iopub.execute_input":"2022-05-14T16:01:00.31637Z","iopub.status.idle":"2022-05-14T16:01:00.328408Z","shell.execute_reply.started":"2022-05-14T16:01:00.316331Z","shell.execute_reply":"2022-05-14T16:01:00.327514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def training(model, optimizer):\n    model.to(DEVICE)\n    model.train()\n    dataloader = loader\n    running_loss = 0.\n    epochs = 1\n    for epoch in range(epochs):\n        print(epoch)\n        for batch in tqdm(dataloader):\n                toxinps, civinps, toxmask, civmask = batch  \n                toxinps, civinps, toxmask, civmask = toxinps.to(DEVICE), civinps.to(DEVICE), toxmask.to(DEVICE), civmask.to(DEVICE)\n#                 y = civinps\n#                 y_ids = y[:, :-1].contiguous()\n#                 lm_labels = y[:, 1:].clone().detach()\n#                 lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n                loss = model(input_ids = toxinps, attention_mask = toxmask, decoder_attention_mask=civmask, labels=civinps).loss\n                \n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n                running_loss += loss.item()\n        epoch_loss = running_loss / len(dataloader)\n\n        print('Loss: ' + str(epoch_loss))\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:01:02.773007Z","iopub.execute_input":"2022-05-14T16:01:02.773267Z","iopub.status.idle":"2022-05-14T16:01:02.78099Z","shell.execute_reply.started":"2022-05-14T16:01:02.773236Z","shell.execute_reply":"2022-05-14T16:01:02.780294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training(model, adamw_optimizer)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\ntext = 'classify: ты самый красивый'\ncomm = tokenizer.encode_plus(text, return_attention_mask=True, return_tensors='pt')\ncomm.input_ids = comm.input_ids.to(DEVICE)\ncomm.attention_mask = comm.attention_mask.to(DEVICE)\n\ngenerated_ids = model.generate(\n              input_ids = comm.input_ids,\n              attention_mask = comm.attention_mask, \n              max_length=150, \n              repetition_penalty=2.5, \n              length_penalty=1.0, \n              early_stopping=True\n              )\n#generated_ids\ntokenizer.decode(generated_ids[0])","metadata":{"execution":{"iopub.status.busy":"2022-05-14T12:51:32.787164Z","iopub.execute_input":"2022-05-14T12:51:32.78742Z","iopub.status.idle":"2022-05-14T12:51:32.864888Z","shell.execute_reply.started":"2022-05-14T12:51:32.787391Z","shell.execute_reply":"2022-05-14T12:51:32.864179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/labeled-toxic-comments/train.tsv', sep='\\t')\ndf = df[['toxic_comment', 'neutral_comment1']]\ndf.dropna(inplace=True)\ndf.columns = ['toxic', 'civil']\ndf[\"toxic\"] = df[\"toxic\"].apply(lambda x: re.sub('\\w*\\d\\w*', ' ', x))\ndf[\"toxic\"] = df[\"toxic\"].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x))\ndf[\"civil\"] = df[\"civil\"].apply(lambda x: re.sub('\\w*\\d\\w*', ' ', x))\ndf[\"civil\"] = df[\"civil\"].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x))\ndf['toxic'] = 'detox: '+df['toxic']","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:39:45.699783Z","iopub.execute_input":"2022-05-14T16:39:45.700516Z","iopub.status.idle":"2022-05-14T16:39:46.085964Z","shell.execute_reply.started":"2022-05-14T16:39:45.700479Z","shell.execute_reply":"2022-05-14T16:39:46.085224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def to_torch_dataset(toxic: pd.Series, civil: pd.Series, tokenizer,\n                             DEVICE) -> TensorDataset:\n    input_ids1 = []\n    input_ids2 = []\n    att_masks1 = []\n    att_masks2 = []\n    \n    for tox, civ in tqdm(zip(toxic, civil)):\n        encoded_dict1 = tokenizer.encode_plus(tox, max_length=512,\n                                              pad_to_max_length=True,\n                                              return_attention_mask=True, return_tensors='pt', truncation=True)\n        input_ids1.append(encoded_dict1['input_ids'])\n        att_masks1.append(encoded_dict1['attention_mask'])\n\n        encoded_dict2 = tokenizer.encode_plus(civ, max_length=512,\n                                              pad_to_max_length=True,\n                                              return_attention_mask=True, return_tensors='pt', truncation=True)\n        input_ids2.append(encoded_dict2['input_ids'])\n        att_masks2.append(encoded_dict2['attention_mask'])\n\n\n    input_ids1 = torch.cat(input_ids1, dim=0)\n    input_ids2 = torch.cat(input_ids2, dim=0)\n    att_masks1 = torch.cat(att_masks1, dim=0)\n    att_masks2 = torch.cat(att_masks2, dim=0)\n  \n\n    input_ids1.to(dtype=torch.long)\n    input_ids2.to(dtype=torch.long)\n    att_masks1.to(dtype=torch.long)\n    att_masks2.to(dtype=torch.long)\n    \n\n    return TensorDataset(input_ids1, input_ids2, att_masks1, att_masks2) ","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:39:52.368419Z","iopub.execute_input":"2022-05-14T16:39:52.368672Z","iopub.status.idle":"2022-05-14T16:39:52.378732Z","shell.execute_reply.started":"2022-05-14T16:39:52.36864Z","shell.execute_reply":"2022-05-14T16:39:52.377933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = to_torch_dataset(df.toxic, df.civil, tokenizer, DEVICE)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:39:55.745334Z","iopub.execute_input":"2022-05-14T16:39:55.745626Z","iopub.status.idle":"2022-05-14T16:40:02.700855Z","shell.execute_reply.started":"2022-05-14T16:39:55.745592Z","shell.execute_reply":"2022-05-14T16:40:02.700044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bs = 2\nloader = DataLoader(dataset, batch_size=bs, num_workers=0, shuffle=True)\nadamw_optim = AdamW(model.parameters(), lr=3e-5, eps=1e-8)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:40:11.326462Z","iopub.execute_input":"2022-05-14T16:40:11.326741Z","iopub.status.idle":"2022-05-14T16:40:11.344242Z","shell.execute_reply.started":"2022-05-14T16:40:11.32671Z","shell.execute_reply":"2022-05-14T16:40:11.343404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def training_detox(model, optimizer):\n    model.to(DEVICE)\n    #model.train()\n    \n    dataloader = loader\n    running_loss = 0.\n    epochs = 3\n    for epoch in range(epochs):\n        print(epoch)\n        for batch in tqdm(dataloader):\n                toxinps, civinps, toxmask, civmask = batch  \n                toxinps, civinps, toxmask, civmask = toxinps.to(DEVICE), civinps.to(DEVICE), toxmask.to(DEVICE), civmask.to(DEVICE)\n                y = civinps\n                y_ids = y[:, :-1].contiguous()\n                lm_labels = y[:, 1:].clone().detach()\n                lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n                loss = model(input_ids = toxinps, attention_mask = toxmask, decoder_input_ids=y_ids, labels=lm_labels).loss\n                \n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n                running_loss += loss.item()\n        epoch_loss = running_loss / len(dataloader)\n\n        print('Loss: ' + str(epoch_loss))\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:40:20.834677Z","iopub.execute_input":"2022-05-14T16:40:20.835496Z","iopub.status.idle":"2022-05-14T16:40:20.843636Z","shell.execute_reply.started":"2022-05-14T16:40:20.835455Z","shell.execute_reply":"2022-05-14T16:40:20.84289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_detox(model, adamw_optim)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\ntext = 'detox: блять иди ты нахуй, я твою мать ебал'\ncomm = tokenizer.encode_plus(text, return_attention_mask=True, return_tensors='pt')\ncomm.input_ids = comm.input_ids.to(DEVICE)\ncomm.attention_mask = comm.attention_mask.to(DEVICE)\n\ngenerated_ids = model.generate(\n              input_ids = comm.input_ids,\n              attention_mask = comm.attention_mask, \n              max_length=150, \n              repetition_penalty=2.5, \n              length_penalty=1.0, \n              early_stopping=True\n              )\n#generated_ids\ntokenizer.decode(generated_ids[0])","metadata":{"execution":{"iopub.status.busy":"2022-05-14T17:46:29.358627Z","iopub.execute_input":"2022-05-14T17:46:29.358922Z","iopub.status.idle":"2022-05-14T17:46:29.432996Z","shell.execute_reply.started":"2022-05-14T17:46:29.35889Z","shell.execute_reply":"2022-05-14T17:46:29.432243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/labeled-toxic-comments/test.tsv', sep='\\t')\ndf = df['toxic_comment']\n#df = df.apply(lambda x: re.sub('\\w*\\d\\w*', ' ', x))#Цифры\ndf = df.apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x))#Пунктуация\ndf = 'detox: '+df","metadata":{"execution":{"iopub.status.busy":"2022-05-14T17:47:21.555626Z","iopub.execute_input":"2022-05-14T17:47:21.555916Z","iopub.status.idle":"2022-05-14T17:47:21.580631Z","shell.execute_reply.started":"2022-05-14T17:47:21.555887Z","shell.execute_reply":"2022-05-14T17:47:21.579959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_dataset(toxic: pd.Series, tokenizer,\n                             DEVICE) -> TensorDataset:\n    input_ids1 = []\n    att_masks1 = []\n    \n    for tox in tqdm(toxic):\n        encoded_dict1 = tokenizer.encode_plus(tox, max_length=512,\n                                              pad_to_max_length=True,\n                                              return_attention_mask=True, return_tensors='pt', truncation=True)\n        input_ids1.append(encoded_dict1['input_ids'])\n        att_masks1.append(encoded_dict1['attention_mask'])\n\n    input_ids1 = torch.cat(input_ids1, dim=0)\n    att_masks1 = torch.cat(att_masks1, dim=0)\n  \n\n    input_ids1.to(DEVICE, dtype=torch.long)\n    att_masks1.to(DEVICE, dtype=torch.long)\n    \n\n    return TensorDataset(input_ids1, att_masks1) ","metadata":{"execution":{"iopub.status.busy":"2022-05-14T17:43:06.886471Z","iopub.execute_input":"2022-05-14T17:43:06.887156Z","iopub.status.idle":"2022-05-14T17:43:06.893656Z","shell.execute_reply.started":"2022-05-14T17:43:06.887123Z","shell.execute_reply":"2022-05-14T17:43:06.892949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = test_dataset(df, tokenizer, DEVICE)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T17:47:25.34346Z","iopub.execute_input":"2022-05-14T17:47:25.343768Z","iopub.status.idle":"2022-05-14T17:47:25.763974Z","shell.execute_reply.started":"2022-05-14T17:47:25.343723Z","shell.execute_reply":"2022-05-14T17:47:25.762989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bs = 1\ntest_loader = DataLoader(dataset, batch_size=bs, num_workers=0, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T17:47:28.444999Z","iopub.execute_input":"2022-05-14T17:47:28.445269Z","iopub.status.idle":"2022-05-14T17:47:28.449701Z","shell.execute_reply.started":"2022-05-14T17:47:28.445239Z","shell.execute_reply":"2022-05-14T17:47:28.448671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = []\nmodel.eval()\nwith torch.no_grad():\n       for batch in tqdm(test_loader):\n                toxinps, toxmask = batch  \n                toxinps, toxmask = toxinps.to(DEVICE), toxmask.to(DEVICE)\n\n                generated_ids = model.generate(\n                  input_ids = toxinps,\n                  attention_mask = toxmask, \n                  max_length=150, \n                  num_beams=2,\n                  repetition_penalty=2.5, \n                  length_penalty=1.0, \n                  early_stopping=True\n                  )\n                pred = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n                predictions.append(pred)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T17:47:31.478385Z","iopub.execute_input":"2022-05-14T17:47:31.478932Z","iopub.status.idle":"2022-05-14T17:50:26.905813Z","shell.execute_reply.started":"2022-05-14T17:47:31.478897Z","shell.execute_reply":"2022-05-14T17:50:26.905081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.Series(predictions)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = pd.concat([df, pd.Series(predictions)], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T17:50:31.09649Z","iopub.execute_input":"2022-05-14T17:50:31.09675Z","iopub.status.idle":"2022-05-14T17:50:31.103718Z","shell.execute_reply.started":"2022-05-14T17:50:31.096721Z","shell.execute_reply":"2022-05-14T17:50:31.102877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.columns = ['toxic', 'civil']","metadata":{"execution":{"iopub.status.busy":"2022-05-14T17:50:34.168488Z","iopub.execute_input":"2022-05-14T17:50:34.168781Z","iopub.status.idle":"2022-05-14T17:50:34.173675Z","shell.execute_reply.started":"2022-05-14T17:50:34.16875Z","shell.execute_reply":"2022-05-14T17:50:34.172842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install openpyxl","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.to_excel('t5supervisedwithpretrain.xlsx')","metadata":{"execution":{"iopub.status.busy":"2022-05-14T17:50:37.342897Z","iopub.execute_input":"2022-05-14T17:50:37.343155Z","iopub.status.idle":"2022-05-14T17:50:37.519613Z","shell.execute_reply.started":"2022-05-14T17:50:37.343127Z","shell.execute_reply":"2022-05-14T17:50:37.518938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model, 'modeldetox.pth')","metadata":{"execution":{"iopub.status.busy":"2022-05-14T17:50:58.232122Z","iopub.execute_input":"2022-05-14T17:50:58.232585Z","iopub.status.idle":"2022-05-14T17:50:59.647604Z","shell.execute_reply.started":"2022-05-14T17:50:58.232546Z","shell.execute_reply":"2022-05-14T17:50:59.646865Z"},"trusted":true},"execution_count":null,"outputs":[]}]}