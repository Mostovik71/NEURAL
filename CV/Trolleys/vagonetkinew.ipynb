{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import ViTFeatureExtractor, ViTForImageClassification\nimport os\nimport torch\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm.auto import tqdm\nimport torch.nn as nn\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, Dataset, Subset\nfrom sklearn import model_selection, metrics\nimport cv2\nfrom PIL import Image\nimport random","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-22T07:29:16.585929Z","iopub.execute_input":"2022-05-22T07:29:16.586212Z","iopub.status.idle":"2022-05-22T07:29:24.177764Z","shell.execute_reply.started":"2022-05-22T07:29:16.586141Z","shell.execute_reply":"2022-05-22T07:29:24.176973Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"transform_train = transforms.Compose([\n         transforms.Resize((384, 384)),\n         transforms.ToTensor(),\n         transforms.Normalize(mean=[0.5, 0.5, 0.5], \n                              std=[0.5, 0.5, 0.5]),\n])","metadata":{"execution":{"iopub.status.busy":"2022-05-22T07:29:56.456686Z","iopub.execute_input":"2022-05-22T07:29:56.456958Z","iopub.status.idle":"2022-05-22T07:29:56.462483Z","shell.execute_reply.started":"2022-05-22T07:29:56.456927Z","shell.execute_reply":"2022-05-22T07:29:56.461750Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_data_path = '../input/d/datasets/mostovik71/vagonetkidata/vagonetkinew/train'\ntrain_data = datasets.ImageFolder(train_data_path, transform=transform_train)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-22T07:30:16.352938Z","iopub.execute_input":"2022-05-22T07:30:16.353311Z","iopub.status.idle":"2022-05-22T07:30:16.374803Z","shell.execute_reply.started":"2022-05-22T07:30:16.353274Z","shell.execute_reply":"2022-05-22T07:30:16.374054Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed = 1234):\n     random.seed(seed)\n     \n     os.environ['PYTHONHASHSEED'] = str(seed)\n     \n     np.random.seed(seed)     \n     \n     torch.manual_seed(seed)\n     \n     torch.cuda.manual_seed(seed)\n     \n     torch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2022-05-22T07:30:19.015936Z","iopub.execute_input":"2022-05-22T07:30:19.016254Z","iopub.status.idle":"2022-05-22T07:30:19.021378Z","shell.execute_reply.started":"2022-05-22T07:30:19.016219Z","shell.execute_reply":"2022-05-22T07:30:19.020686Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"seed_everything()","metadata":{"execution":{"iopub.status.busy":"2022-05-22T07:30:40.587055Z","iopub.execute_input":"2022-05-22T07:30:40.587660Z","iopub.status.idle":"2022-05-22T07:30:40.595448Z","shell.execute_reply.started":"2022-05-22T07:30:40.587622Z","shell.execute_reply":"2022-05-22T07:30:40.594652Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"batch_size = 8\ntrain_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=0)\n#val_dataloader = DataLoader(valid_data, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=0)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T07:33:53.406407Z","iopub.execute_input":"2022-05-22T07:33:53.406903Z","iopub.status.idle":"2022-05-22T07:33:53.413269Z","shell.execute_reply.started":"2022-05-22T07:33:53.406863Z","shell.execute_reply":"2022-05-22T07:33:53.410960Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def train_model(model, loss, optimizer, scheduler, num_epochs):\n    dataloader = train_dataloader\n    for epoch in range(num_epochs):\n            print('Epoch {}/{}:'.format(epoch, num_epochs - 1), flush=True)\n       \n            running_loss = 0.\n            running_acc = 0.\n\n            \n            for inputs, labels in tqdm(dataloader):\n                inputs = inputs.to(device)\n                labels = labels.to(device) \n                optimizer.zero_grad()\n                preds = model(inputs).logits\n                loss_value = loss(preds, labels)\n                preds_class = preds.argmax(dim=1)\n                loss_value.backward()\n                optimizer.step()\n                running_loss += loss_value.item()\n                running_acc += (preds_class == labels.data).float().mean()\n\n            epoch_loss = running_loss / len(dataloader)\n            epoch_acc = running_acc / len(dataloader)\n\n            print(epoch_loss, epoch_acc)\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-22T07:34:48.459249Z","iopub.execute_input":"2022-05-22T07:34:48.459517Z","iopub.status.idle":"2022-05-22T07:34:48.468050Z","shell.execute_reply.started":"2022-05-22T07:34:48.459489Z","shell.execute_reply":"2022-05-22T07:34:48.467164Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"model = ViTForImageClassification.from_pretrained('google/vit-base-patch32-384', output_hidden_states=True)\nfor param in model.parameters():\n    param.requires_grad = False\nmodel.classifier = torch.nn.Linear(model.classifier.in_features, 2)\ndevice = 'cuda:0'\nmodel.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\ntrain_model(model, loss, optimizer, scheduler, num_epochs=7)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, image_paths, transform):\n        self.image_paths = image_paths\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        \n        image_filepath = self.image_paths[idx]\n        \n        image = cv2.imread('../input/d/datasets/mostovik71/vagonetkidata/vagonetkinew/test/'+image_filepath)\n    \n        image = Image.fromarray(image)\n        image = self.transform(image)\n       \n        return image, image_filepath","metadata":{"execution":{"iopub.status.busy":"2022-05-22T07:39:40.065252Z","iopub.execute_input":"2022-05-22T07:39:40.065673Z","iopub.status.idle":"2022-05-22T07:39:40.073670Z","shell.execute_reply.started":"2022-05-22T07:39:40.065631Z","shell.execute_reply":"2022-05-22T07:39:40.072971Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"test = os.listdir('../input/d/datasets/mostovik71/vagonetkidata/vagonetkinew/test')","metadata":{"execution":{"iopub.status.busy":"2022-05-22T07:39:42.694610Z","iopub.execute_input":"2022-05-22T07:39:42.695301Z","iopub.status.idle":"2022-05-22T07:39:42.701947Z","shell.execute_reply.started":"2022-05-22T07:39:42.695264Z","shell.execute_reply":"2022-05-22T07:39:42.701232Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"test_dataset = MyDataset(test, transform_train)\ntest_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T07:39:44.338885Z","iopub.execute_input":"2022-05-22T07:39:44.339172Z","iopub.status.idle":"2022-05-22T07:39:44.343721Z","shell.execute_reply.started":"2022-05-22T07:39:44.339141Z","shell.execute_reply":"2022-05-22T07:39:44.343046Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"model.eval()\n\ntest_predictions = []\ntest_img_paths = []\nfor inputs, paths in tqdm(test_dataloader):\n    print(inputs)\n    inputs = inputs.to(device)\n    #labels = labels.to(device)\n    with torch.set_grad_enabled(False):\n        preds = model(inputs).logits\n    test_predictions.append(\n        torch.nn.functional.softmax(preds, dim=1)[:,1].data.cpu().numpy())\n    test_img_paths.extend(paths)\n    \ntest_predictions = np.concatenate(test_predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean = np.array([0.5, 0.5, 0.5])\nstd = np.array([0.5, 0.5, 0.5])","metadata":{"execution":{"iopub.status.busy":"2022-05-22T07:40:09.698917Z","iopub.execute_input":"2022-05-22T07:40:09.699199Z","iopub.status.idle":"2022-05-22T07:40:09.703582Z","shell.execute_reply.started":"2022-05-22T07:40:09.699169Z","shell.execute_reply":"2022-05-22T07:40:09.702900Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"def show_input(input_tensor, title=''):\n    image = input_tensor.permute(1, 2, 0).numpy()\n    image = std * image + mean\n    plt.imshow(image)\n    plt.title(title)\n    plt.show()\n    plt.pause(0.001)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T07:40:12.195352Z","iopub.execute_input":"2022-05-22T07:40:12.195623Z","iopub.status.idle":"2022-05-22T07:40:12.200632Z","shell.execute_reply.started":"2022-05-22T07:40:12.195592Z","shell.execute_reply":"2022-05-22T07:40:12.199877Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"inputs, labels = next(iter(test_dataloader))\n\nfor img, pred in zip(inputs, test_predictions):\n    show_input(img, title=pred)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T07:40:22.116407Z","iopub.execute_input":"2022-05-22T07:40:22.116667Z","iopub.status.idle":"2022-05-22T07:40:24.251807Z","shell.execute_reply.started":"2022-05-22T07:40:22.116640Z","shell.execute_reply":"2022-05-22T07:40:24.251128Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}